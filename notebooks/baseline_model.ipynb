{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyV7jC7RgbBp"
      },
      "source": [
        "### **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H3yzYA4igds_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbfcHdUsgh-L"
      },
      "source": [
        "### **Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OfeKiClXgjFK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded successfully.\n",
            "Training samples: 2180\n",
            "Test samples: 546\n"
          ]
        }
      ],
      "source": [
        "# Define paths relative to the notebook's location\n",
        "train_path = '../data/processed/train_data.csv'\n",
        "test_path = '../data/processed/test_data.csv'\n",
        "\n",
        "# Load the datasets\n",
        "try:\n",
        "    train_df = pd.read_csv(train_path)\n",
        "    test_df = pd.read_csv(test_path)\n",
        "    print(\"Data loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Data files not found.\")\n",
        "    print(f\"Make sure '{train_path}' and '{test_path}' exist.\")\n",
        "    print(\"Have you run 'python src/preprocessing.py' first?\")\n",
        "\n",
        "# Prepare data and handle potential NaNs (from empty sentences)\n",
        "X_train = train_df['processed_sentence'].fillna('')\n",
        "y_train = train_df['sentiment']\n",
        "\n",
        "X_test = test_df['processed_sentence'].fillna('')\n",
        "y_test = test_df['sentiment']\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Test samples: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv2FtCamgoL7"
      },
      "source": [
        "### **Feature Engineering (TF-IDF)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iueEnJwwgrgP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting TF-IDF vectorizer on training data...\n",
            "Transforming train and test data...\n",
            "TF-IDF feature matrix shape (Train): (2180, 3571)\n"
          ]
        }
      ],
      "source": [
        "# Initialize the TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# 1. Fit the vectorizer ONLY on the training data\n",
        "print(\"Fitting TF-IDF vectorizer on training data...\")\n",
        "vectorizer.fit(X_train)\n",
        "\n",
        "# 2. Transform both the training and test data\n",
        "print(\"Transforming train and test data...\")\n",
        "X_train_tfidf = vectorizer.transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"TF-IDF feature matrix shape (Train): {X_train_tfidf.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsmoNT__gwhX"
      },
      "source": [
        "### **Train Baseline Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "t9ekeRjPgxuC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training DummyClassifier...\n",
            "Model training complete.\n"
          ]
        }
      ],
      "source": [
        "print(\"Training DummyClassifier...\")\n",
        "\n",
        "# Initialize the classifier\n",
        "# 'stratified' predicts randomly, maintaining the training set's class distribution\n",
        "dummy_model = DummyClassifier(strategy='stratified', random_state=42)\n",
        "\n",
        "# Train the model\n",
        "dummy_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(\"Model training complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYNQrRbHg1ig"
      },
      "source": [
        "### **Evaluate Baseline Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cayJFE3ag3Xc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model...\n",
            "\n",
            "--- Baseline Model Evaluation ---\n",
            "Accuracy:  0.5220\n",
            "Precision: 0.5267\n",
            "Recall:    0.5018\n",
            "F1-Score:  0.5140\n",
            "\n",
            "--- Classification Report ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Negative (0)       0.52      0.54      0.53       271\n",
            "Positive (1)       0.53      0.50      0.51       275\n",
            "\n",
            "    accuracy                           0.52       546\n",
            "   macro avg       0.52      0.52      0.52       546\n",
            "weighted avg       0.52      0.52      0.52       546\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Evaluating model...\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = dummy_model.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate individual metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n--- Baseline Model Evaluation ---\")\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1-Score:  {f1:.4f}\")\n",
        "\n",
        "# Print a full classification report\n",
        "print(\"\\n--- Classification Report ---\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Negative (0)', 'Positive (1)']))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
