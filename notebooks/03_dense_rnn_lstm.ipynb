{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f98a0da",
   "metadata": {},
   "source": [
    "# **Enviroment Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6f6c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 08:06:36.475939: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-20 08:06:36.524757: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 08:06:37.832618: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# --- Scikit-Learn Imports ---\n",
    "# For TF-IDF (DNN model)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# For evaluation\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# --- TensorFlow/Keras Imports ---\n",
    "# For Tokenization (RNN/LSTM models)\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# For Building Models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, SimpleRNN, LSTM, SpatialDropout1D, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "print(\"All libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca83ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_path = '../data/processed/train_data.csv'\n",
    "test_output_path = '../data/processed/test_data.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_output_path)\n",
    "test_df = pd.read_csv(test_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2f9c96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 2180\n",
      "Test samples: 546\n",
      "\n",
      "--- Training Data Example ---\n",
      "0       dont trust website dont expect helpful support\n",
      "1               film terrible credit version watchable\n",
      "2          really recommend place go wrong donut place\n",
      "3    memory murky say enjoy every single episode pr...\n",
      "4       headset work great package nicely avoid damage\n",
      "Name: processed_sentence, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Prepare data and handle potential NaNs (from empty sentences)\n",
    "X_train = train_df['processed_sentence'].fillna('')\n",
    "y_train = train_df['sentiment']\n",
    "\n",
    "X_test = test_df['processed_sentence'].fillna('')\n",
    "y_test = test_df['sentiment']\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(\"\\n--- Training Data Example ---\")\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef28cf29",
   "metadata": {},
   "source": [
    "# **Dense Neural Network (DNN)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0b1e06",
   "metadata": {},
   "source": [
    "## **Vectorization (TF-IDF)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff60002e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing and fitting TF-IDF Vectorizer...\n",
      "TF-IDF vectorization complete.\n",
      "Vocabulary size: 3571\n",
      "Training data shape: (2180, 3571)\n",
      "Test data shape: (546, 3571)\n"
     ]
    }
   ],
   "source": [
    "# We will use TF-IDF to convert the text into numerical vectors\n",
    "# for our Dense network.\n",
    "\n",
    "print(\"Initializing and fitting TF-IDF Vectorizer...\")\n",
    "\n",
    "# Initialize the vectorizer\n",
    "# max_features limits the vocabulary to the top 5000 words\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# 1. Fit the vectorizer ONLY on the training data\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "# 2. Transform both the training and test data\n",
    "X_train_tfidf = vectorizer.transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Convert from sparse matrix to dense array for Keras\n",
    "X_train_tfidf = X_train_tfidf.toarray()\n",
    "X_test_tfidf = X_test_tfidf.toarray()\n",
    "\n",
    "# Get the vocabulary size (this is our input dimension)\n",
    "vocab_size = X_train_tfidf.shape[1]\n",
    "\n",
    "print(f\"TF-IDF vectorization complete.\")\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Training data shape: {X_train_tfidf.shape}\")\n",
    "print(f\"Test data shape: {X_test_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdccca3",
   "metadata": {},
   "source": [
    "## **Building the DNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d509088e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">228,608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m228,608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">230,721</span> (901.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m230,721\u001b[0m (901.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">230,721</span> (901.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m230,721\u001b[0m (901.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We'll use a simple Sequential model\n",
    "dnn_model = Sequential()\n",
    "\n",
    "# Input Layer\n",
    "# The input_dim must match our vocabulary size from TF-IDF\n",
    "dnn_model.add(Dense(64, activation='relu', input_dim=vocab_size))\n",
    "dnn_model.add(Dropout(0.5)) # Dropout helps prevent overfitting\n",
    "\n",
    "# Hidden Layer\n",
    "dnn_model.add(Dense(32, activation='relu'))\n",
    "dnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Output Layer\n",
    "# We use 1 neuron with 'sigmoid' activation for binary (0 or 1) classification\n",
    "dnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "dnn_model.compile(\n",
    "    loss='binary_crossentropy', # Best loss function for binary classification\n",
    "    optimizer='adam',           # A standard, effective optimizer\n",
    "    metrics=['accuracy']        # We want to track accuracy\n",
    ")\n",
    "\n",
    "# Print a summary of the model's architecture\n",
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a808c451",
   "metadata": {},
   "source": [
    "## **Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48771a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the DNN model...\n",
      "Epoch 1/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5143 - loss: 0.6923 - val_accuracy: 0.6170 - val_loss: 0.6881\n",
      "Epoch 2/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6347 - loss: 0.6741 - val_accuracy: 0.6468 - val_loss: 0.6616\n",
      "Epoch 3/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7317 - loss: 0.6071 - val_accuracy: 0.7729 - val_loss: 0.5806\n",
      "Epoch 4/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8727 - loss: 0.4539 - val_accuracy: 0.7844 - val_loss: 0.4778\n",
      "Epoch 5/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.3086 - val_accuracy: 0.7752 - val_loss: 0.4435\n",
      "Epoch 6/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9472 - loss: 0.2084 - val_accuracy: 0.7775 - val_loss: 0.4456\n",
      "Epoch 7/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.1507 - val_accuracy: 0.7775 - val_loss: 0.4647\n",
      "Epoch 8/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9748 - loss: 0.1243 - val_accuracy: 0.7821 - val_loss: 0.4932\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the DNN model...\")\n",
    "\n",
    "# We use EarlyStopping to stop training once the model\n",
    "# isn't improving, which helps prevent overfitting.\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', # Watch the validation loss\n",
    "    patience=3,         # Stop after 3 epochs of no improvement\n",
    "    restore_best_weights=True # Go back to the best version of the model\n",
    ")\n",
    "\n",
    "# We use 20% of our training data as a 'validation' set\n",
    "# to monitor for overfitting\n",
    "history = dnn_model.fit(\n",
    "    X_train_tfidf,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2, # Use 20% of training data for validation\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536d461b",
   "metadata": {},
   "source": [
    "## **Evaluate the DNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a745fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DNN Model Evaluation (Test Set) ---\n",
      "Test Accuracy: 0.8150\n",
      "Test Loss:     0.4163\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Negative (0)       0.81      0.82      0.82       271\n",
      "Positive (1)       0.82      0.81      0.81       275\n",
      "\n",
      "    accuracy                           0.82       546\n",
      "   macro avg       0.82      0.82      0.82       546\n",
      "weighted avg       0.82      0.82      0.82       546\n",
      "\n",
      "\n",
      "Baseline Accuracy was: 0.5220\n",
      "DNN Accuracy is:     0.8150\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = dnn_model.evaluate(X_test_tfidf, y_test, verbose=0)\n",
    "\n",
    "print(\"\\n--- DNN Model Evaluation (Test Set) ---\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Loss:     {loss:.4f}\")\n",
    "\n",
    "# Get detailed predictions\n",
    "# We must round the sigmoid output (e.g., 0.8 -> 1, 0.3 -> 0)\n",
    "y_pred_probs = dnn_model.predict(X_test_tfidf)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# Print a full classification report\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Negative (0)', 'Positive (1)']))\n",
    "\n",
    "# Compare to baseline\n",
    "print(f\"\\nBaseline Accuracy was: 0.5220\")\n",
    "print(f\"DNN Accuracy is:     {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1328b88b",
   "metadata": {},
   "source": [
    "## **Tuning DNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd48afc",
   "metadata": {},
   "source": [
    "### Create a Model-Building Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285f3a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension set to: 3571\n"
     ]
    }
   ],
   "source": [
    "# We need the input dimension from our TF-IDF vectors\n",
    "# This must be defined before the function\n",
    "try:\n",
    "    input_dim = X_train_tfidf.shape[1]\n",
    "    print(f\"Input dimension set to: {input_dim}\")\n",
    "except NameError:\n",
    "    print(\"Error: 'X_train_tfidf' is not defined.\")\n",
    "    print(\"Please run the TF-IDF vectorization cell first.\")\n",
    "\n",
    "def create_dnn_model(hidden_units=64, dropout_rate=0.5, optimizer='adam'):\n",
    "    \"\"\"\n",
    "    Builds and compiles a Keras DNN model.\n",
    "    This function will be called by GridSearchCV.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input Layer (with tunable parameters)\n",
    "    model.add(Dense(hidden_units, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Hidden Layer (we'll keep this one fixed for the example)\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048de865",
   "metadata": {},
   "source": [
    "### **Define the Parameter Grid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa551d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter grid defined:\n",
      "{'batch_size': [32, 64], 'epochs': [10, 20], 'model__hidden_units': [32, 64], 'model__dropout_rate': [0.3, 0.5], 'model__optimizer': ['adam', 'rmsprop']}\n"
     ]
    }
   ],
   "source": [
    "# 1. Wrap the model builder using KerasClassifier\n",
    "# We pass any parameters here that we are NOT tuning in the grid\n",
    "keras_model = KerasClassifier(\n",
    "    model=create_dnn_model,\n",
    "    verbose=0 # Suppresses epoch logging during grid search\n",
    ")\n",
    "\n",
    "# 2. Define the grid of parameters to test\n",
    "# WARNING: A large grid can take a very long time to run.\n",
    "# This is a small, example grid for speed.\n",
    "param_grid = {\n",
    "    'batch_size': [32, 64],\n",
    "    'epochs': [10, 20],\n",
    "    'model__hidden_units': [32, 64],\n",
    "    'model__dropout_rate': [0.3, 0.5],\n",
    "    'model__optimizer': ['adam', 'rmsprop']\n",
    "}\n",
    "\n",
    "print(\"Parameter grid defined:\")\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4e41c4",
   "metadata": {},
   "source": [
    "### Run the Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dcccad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search... (This may take a while)\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 19:27:08.048817: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:08.049170: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:08.110814: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-09 19:27:08.118393: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:08.118874: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:08.149810: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:08.150279: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:08.186755: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-09 19:27:08.186791: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:08.187147: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:08.212361: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-09 19:27:08.229661: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:08.230136: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:08.256400: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:08.256952: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:08.267471: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-09 19:27:08.291350: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:08.292066: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:08.303353: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-09 19:27:08.328289: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-09 19:27:08.332283: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:08.332931: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:08.352108: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-09 19:27:08.365172: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:08.365696: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:08.371467: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:08.371664: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:08.371923: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:08.372145: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:08.399231: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:08.400436: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:08.422753: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-09 19:27:08.435189: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-09 19:27:08.437203: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-09 19:27:08.441731: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-09 19:27:08.468544: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-09 19:27:09.791227: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:09.791994: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:09.961838: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:09.962501: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:10.143302: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:10.143974: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:10.187556: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:10.188190: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:10.293991: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:10.294690: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:10.317583: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:10.318232: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:10.393415: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:10.394059: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:10.394289: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:10.394640: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:10.498588: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:10.499204: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:10.542388: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:10.542991: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:10.572156: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:10.572742: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-09 19:27:10.643673: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-09 19:27:10.645330: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762734430.853901   90285 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1762734430.870052   90285 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762734430.902155   90287 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1762734430.919886   90287 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762734431.015792   90281 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1762734431.030252   90281 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762734431.057655   90286 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1762734431.069465   90286 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762734431.203864   90289 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1762734431.218373   90289 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762734431.278539   90288 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1762734431.292280   90288 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762734431.375534   90279 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "W0000 00:00:1762734431.392993   90279 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762734431.418703   90283 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "W0000 00:00:1762734431.434557   90283 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762734431.489907   90280 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762734431.512930   90284 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1762734431.516225   90280 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "W0000 00:00:1762734431.528214   90284 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762734431.593376   90282 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1762734431.606904   90282 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762734431.684831   90278 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1762734431.699583   90278 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=rmsprop; total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=adam; total time=   6.1s\n",
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=rmsprop; total time=   6.1s\n",
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=rmsprop; total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=adam; total time=   6.6s\n",
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=rmsprop; total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=adam; total time=   6.8s\n",
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=rmsprop; total time=   7.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=adam; total time=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=adam; total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=rmsprop; total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=adam; total time=   8.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=rmsprop; total time=   5.6s\n",
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=rmsprop; total time=   4.8s\n",
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=rmsprop; total time=   4.9s\n",
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=adam; total time=   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=adam; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=adam; total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=adam; total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=rmsprop; total time=   6.7s\n",
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=rmsprop; total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=adam; total time=   8.0s\n",
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=rmsprop; total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=10, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=adam; total time=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=rmsprop; total time=   9.8s\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=adam; total time=  10.1s\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=rmsprop; total time=   8.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=rmsprop; total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=adam; total time=  10.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=adam; total time=  11.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=rmsprop; total time=  10.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=adam; total time=  12.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=rmsprop; total time=  11.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=adam; total time=  12.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=rmsprop; total time=  11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=adam; total time=  13.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=adam; total time=  10.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=adam; total time=  10.7s\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=rmsprop; total time=  10.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=rmsprop; total time=  10.4s\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=rmsprop; total time=   9.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=adam; total time=  11.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=rmsprop; total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=rmsprop; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=adam; total time=   5.2s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=adam; total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=rmsprop; total time=   5.2s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=adam; total time=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=adam; total time=  13.6s\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=adam; total time=  13.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=rmsprop; total time=  12.7s\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=rmsprop; total time=  12.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=rmsprop; total time=  12.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=adam; total time=  14.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=adam; total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=rmsprop; total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=rmsprop; total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=adam; total time=   7.0s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=adam; total time=   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=rmsprop; total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=rmsprop; total time=   4.5s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=adam; total time=   4.9s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=rmsprop; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=adam; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=rmsprop; total time=   5.0s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=adam; total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=adam; total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=adam; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=rmsprop; total time=   4.5s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=rmsprop; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=adam; total time=   5.3s\n",
      "[CV] END batch_size=64, epochs=10, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=rmsprop; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=adam; total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=adam; total time=   7.1s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=rmsprop; total time=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=adam; total time=   7.7s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=rmsprop; total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.3, model__hidden_units=32, model__optimizer=rmsprop; total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=rmsprop; total time=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=adam; total time=   9.9s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=adam; total time=   9.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=adam; total time=   9.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=rmsprop; total time=   9.2s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.3, model__hidden_units=64, model__optimizer=rmsprop; total time=   9.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=rmsprop; total time=   6.5s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=rmsprop; total time=   6.7s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=adam; total time=   7.9s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=rmsprop; total time=   7.1s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=adam; total time=   7.8s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.5, model__hidden_units=32, model__optimizer=adam; total time=   8.0s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=rmsprop; total time=   5.4s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=rmsprop; total time=   5.3s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=adam; total time=   6.7s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=adam; total time=   6.0s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=adam; total time=   6.2s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.5, model__hidden_units=64, model__optimizer=rmsprop; total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo965/Documents/Universidad/8-sem/CEDIII/IntegrativeTasks/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search complete.\n"
     ]
    }
   ],
   "source": [
    "# Initialize GridSearchCV\n",
    "# cv=3 -> 3-fold cross-validation\n",
    "# n_jobs=-1 -> Use all available CPU cores\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=keras_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2 # Show progress\n",
    ")\n",
    "\n",
    "print(\"Starting Grid Search... (This may take a while)\")\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Grid Search complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a9a07a",
   "metadata": {},
   "source": [
    "### Review Tuning Results and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb03c575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cross-Validation Accuracy: 0.8005\n",
      "\n",
      "Best Parameters found:\n",
      "{'batch_size': 64, 'epochs': 20, 'model__dropout_rate': 0.5, 'model__hidden_units': 64, 'model__optimizer': 'rmsprop'}\n",
      "\n",
      "Evaluating the tuned model on the TEST set...\n",
      "\n",
      "Original DNN Accuracy: 0.8095\n",
      "Tuned DNN Accuracy:    0.8187\n",
      "\n",
      "--- Tuned Model Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Negative (0)       0.85      0.77      0.81       271\n",
      "Positive (1)       0.79      0.87      0.83       275\n",
      "\n",
      "    accuracy                           0.82       546\n",
      "   macro avg       0.82      0.82      0.82       546\n",
      "weighted avg       0.82      0.82      0.82       546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "print(\"\\nBest Parameters found:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# 'grid_search.best_estimator_' is the final model,\n",
    "# retrained on the *entire* training set using the best parameters.\n",
    "best_dnn_model = grid_search.best_estimator_\n",
    "\n",
    "# --- Final Evaluation on the Test Set ---\n",
    "print(\"\\nEvaluating the tuned model on the TEST set...\")\n",
    "y_pred_tuned = best_dnn_model.predict(X_test_tfidf)\n",
    "\n",
    "# Get the new accuracy\n",
    "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "\n",
    "print(f\"\\nOriginal DNN Accuracy: 0.8095\")\n",
    "print(f\"Tuned DNN Accuracy:    {accuracy_tuned:.4f}\")\n",
    "\n",
    "# Print a full classification report\n",
    "print(\"\\n--- Tuned Model Classification Report ---\")\n",
    "print(classification_report(y_test, y_pred_tuned, target_names=['Negative (0)', 'Positive (1)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba134e63",
   "metadata": {},
   "source": [
    "# **Long short-term memory Neural Network (LSTM)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cvsn08b7y6",
   "metadata": {},
   "source": [
    "## **Text Tokenization and Padding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3qsumbznc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For LSTM models, we need to convert text into sequences of integers\n",
    "# and then pad them to ensure uniform length.\n",
    "\n",
    "print(\"Initializing tokenizer for LSTM...\")\n",
    "\n",
    "# Initialize the tokenizer with a vocabulary size limit\n",
    "# Using 4000 words to balance between coverage and overfitting prevention\n",
    "vocab_size_lstm = 4000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size_lstm, oov_token='<OOV>')\n",
    "\n",
    "# Fit the tokenizer ONLY on training data\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert text to sequences of integers\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Calculate max sequence length using 95th percentile (anti-overfitting measure)\n",
    "# This prevents outliers from forcing unnecessary padding\n",
    "sequence_lengths = [len(seq) for seq in X_train_seq]\n",
    "max_length = int(np.percentile(sequence_lengths, 95))\n",
    "\n",
    "print(f\"\\nSequence Length Statistics:\")\n",
    "print(f\"  Min length: {np.min(sequence_lengths)}\")\n",
    "print(f\"  Max length: {np.max(sequence_lengths)}\")\n",
    "print(f\"  Mean length: {np.mean(sequence_lengths):.2f}\")\n",
    "print(f\"  95th percentile: {max_length}\")\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_length, padding='post', truncating='post')\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "# Print tokenization results\n",
    "actual_vocab_size = len(tokenizer.word_index) + 1  # +1 for padding token\n",
    "print(f\"\\nTokenization Complete!\")\n",
    "print(f\"  Vocabulary size (actual): {actual_vocab_size}\")\n",
    "print(f\"  Vocabulary size (used): {min(actual_vocab_size, vocab_size_lstm)}\")\n",
    "print(f\"  Max sequence length: {max_length}\")\n",
    "print(f\"  Training data shape: {X_train_padded.shape}\")\n",
    "print(f\"  Test data shape: {X_test_padded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sjf2i6byx7q",
   "metadata": {},
   "source": [
    "## **Building the LSTM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1y2re21li9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(vocab_size, embedding_dim=50, lstm_units=64, dropout_rate=0.5, optimizer='adam'):\n",
    "    \"\"\"\n",
    "    Creates a simple LSTM model for sentiment classification.\n",
    "    \n",
    "    ANTI-OVERFITTING MEASURES:\n",
    "    - Small embedding dimension (50)\n",
    "    - Single LSTM layer (avoids deep architecture overfitting)\n",
    "    - Aggressive dropout (0.5 default)\n",
    "    - SpatialDropout1D for embeddings\n",
    "    - L2 regularization on Dense layer\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    vocab_size : int\n",
    "        Size of the vocabulary\n",
    "    embedding_dim : int\n",
    "        Dimension of word embeddings (default: 50)\n",
    "    lstm_units : int\n",
    "        Number of LSTM units (default: 64)\n",
    "    dropout_rate : float\n",
    "        Dropout rate (default: 0.5)\n",
    "    optimizer : str\n",
    "        Optimizer to use (default: 'adam')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    model : Sequential\n",
    "        Compiled LSTM model\n",
    "    \"\"\"\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    model = Sequential([\n",
    "        # Embedding layer - learns word representations\n",
    "        Embedding(input_dim=vocab_size, \n",
    "                  output_dim=embedding_dim, \n",
    "                  input_length=max_length,\n",
    "                  name='embedding_layer'),\n",
    "        \n",
    "        # Spatial dropout for embeddings (more effective than regular dropout)\n",
    "        SpatialDropout1D(dropout_rate * 0.4, name='spatial_dropout'),\n",
    "        \n",
    "        # Single LSTM layer - AVOID stacking multiple LSTMs (causes overfitting)\n",
    "        LSTM(units=lstm_units, \n",
    "             dropout=dropout_rate * 0.4,              # Recurrent dropout\n",
    "             recurrent_dropout=dropout_rate * 0.3,    # Additional recurrent dropout\n",
    "             name='lstm_layer'),\n",
    "        \n",
    "        # Regular dropout before dense layer\n",
    "        Dropout(dropout_rate, name='dropout'),\n",
    "        \n",
    "        # Output layer with L2 regularization\n",
    "        Dense(1, activation='sigmoid', \n",
    "              kernel_regularizer=tf.keras.regularizers.l2(0.001),\n",
    "              name='output_layer')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create a sample model to visualize architecture\n",
    "print(\"Building LSTM Model Architecture...\\n\")\n",
    "sample_lstm_model = create_lstm_model(\n",
    "    vocab_size=min(actual_vocab_size, vocab_size_lstm), \n",
    "    embedding_dim=50, \n",
    "    lstm_units=64\n",
    ")\n",
    "\n",
    "# Build the model explicitly with input shape to show parameters\n",
    "sample_lstm_model.build(input_shape=(None, max_length))\n",
    "\n",
    "print(sample_lstm_model.summary())\n",
    "print(\"\\nLSTM model architecture defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gitjhgajlnq",
   "metadata": {},
   "source": [
    "## **Hyperparameter Tuning with GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x80x006eppb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store parameters as constants to avoid serialization issues\n",
    "LSTM_VOCAB_SIZE = min(actual_vocab_size, vocab_size_lstm)\n",
    "LSTM_MAX_LENGTH = max_length\n",
    "\n",
    "# Wrap the model for sklearn compatibility\n",
    "def create_model_wrapper(embedding_dim=50, lstm_units=64, dropout_rate=0.5, optimizer='adam'):\n",
    "    \"\"\"\n",
    "    Wrapper function for KerasClassifier.\n",
    "    Uses module-level constants to avoid serialization issues with multiprocessing.\n",
    "    \"\"\"\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Dropout, Input\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add Input layer explicitly to ensure model is properly built\n",
    "    model.add(Input(shape=(LSTM_MAX_LENGTH,)))\n",
    "    \n",
    "    # Embedding layer - learns word representations\n",
    "    model.add(Embedding(input_dim=LSTM_VOCAB_SIZE, \n",
    "                        output_dim=embedding_dim))\n",
    "    \n",
    "    # Spatial dropout for embeddings (more effective than regular dropout)\n",
    "    model.add(SpatialDropout1D(dropout_rate * 0.4))\n",
    "    \n",
    "    # Single LSTM layer - AVOID stacking multiple LSTMs (causes overfitting)\n",
    "    model.add(LSTM(units=lstm_units, \n",
    "                   dropout=dropout_rate * 0.4,              # Recurrent dropout\n",
    "                   recurrent_dropout=dropout_rate * 0.3))   # Additional recurrent dropout\n",
    "    \n",
    "    # Regular dropout before dense layer\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Output layer with L2 regularization\n",
    "    model.add(Dense(1, activation='sigmoid', \n",
    "                    kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create KerasClassifier wrapper\n",
    "keras_lstm_model = KerasClassifier(\n",
    "    model=create_model_wrapper,\n",
    "    embedding_dim=50,\n",
    "    lstm_units=64,\n",
    "    dropout_rate=0.5,\n",
    "    optimizer='adam',\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# MINIMAL parameter grid - quality over quantity\n",
    "# This grid focuses on the most impactful parameters while keeping combinations manageable\n",
    "param_grid = {\n",
    "    'batch_size': [32, 64],                        # 2 values - batch size affects convergence\n",
    "    'epochs': [15, 20],                            # 2 values - training duration\n",
    "    'model__embedding_dim': [50],                  # 1 value - keep fixed (50 is optimal)\n",
    "    'model__lstm_units': [64, 96],                 # 2 values - small sizes only to prevent overfitting\n",
    "    'model__dropout_rate': [0.4, 0.5],             # 2 values - aggressive dropout\n",
    "    'model__optimizer': ['adam']                    # 1 value - adam is best for this task\n",
    "}\n",
    "\n",
    "# Calculate total combinations\n",
    "total_combinations = np.prod([len(v) for v in param_grid.values()])\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"HYPERPARAMETER TUNING SETUP\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nParameter grid:\")\n",
    "for key, value in param_grid.items():\n",
    "    print(f\"  {key:.<30} {value}\")\n",
    "print(f\"\\nTotal combinations to test: {total_combinations}\")\n",
    "print(f\"Cross-validation folds: 3\")\n",
    "print(f\"Total model trainings: {total_combinations * 3}\")\n",
    "print(f\"\\nEstimated time: 15-30 minutes (depending on hardware)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4la1rljqw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GridSearchCV\n",
    "# NOTE: Using n_jobs=1 to avoid multiprocessing serialization issues with Keras models\n",
    "grid_search_lstm = GridSearchCV(\n",
    "    estimator=keras_lstm_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,                    # 3-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    n_jobs=1,                # Sequential execution (avoids serialization issues)\n",
    "    verbose=2,               # Show progress\n",
    "    return_train_score=True  # Track training scores to detect overfitting\n",
    ")\n",
    "\n",
    "print(\"\\nStarting Grid Search for LSTM...\")\n",
    "print(\"Using 3-fold cross-validation with aggressive regularization...\")\n",
    "print(\"NOTE: Running sequentially (n_jobs=1) to avoid serialization issues.\")\n",
    "print(\"This will take some time. Please be patient.\\n\")\n",
    "\n",
    "# Fit the grid search\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "grid_search_lstm.fit(X_train_padded, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Grid Search complete!\")\n",
    "print(f\"Time elapsed: {elapsed_time/60:.2f} minutes\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "erjkmsgr1ov",
   "metadata": {},
   "source": [
    "### Review Tuning Results and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oigjbtt02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display best parameters and CV score\n",
    "print(\"=\"*60)\n",
    "print(\"GRID SEARCH RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBest Cross-Validation Accuracy: {grid_search_lstm.best_score_:.4f}\")\n",
    "print(\"\\nBest Parameters found:\")\n",
    "for param, value in grid_search_lstm.best_params_.items():\n",
    "    print(f\"  {param:.<35} {value}\")\n",
    "\n",
    "# Analyze CV results to check for overfitting\n",
    "cv_results = pd.DataFrame(grid_search_lstm.cv_results_)\n",
    "cv_results_sorted = cv_results.sort_values('rank_test_score')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP 5 PARAMETER COMBINATIONS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nRank | Test Score | Train Score | Std Dev | Parameters\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for i, idx in enumerate(cv_results_sorted.head(5).index, 1):\n",
    "    test_score = cv_results_sorted.loc[idx, 'mean_test_score']\n",
    "    train_score = cv_results_sorted.loc[idx, 'mean_train_score']\n",
    "    std_score = cv_results_sorted.loc[idx, 'std_test_score']\n",
    "    params = cv_results_sorted.loc[idx, 'params']\n",
    "    \n",
    "    print(f\"{i:>4} | {test_score:.4f}     | {train_score:.4f}      | {std_score:.4f}  | {params}\")\n",
    "\n",
    "# Check for overfitting: if mean_train_score >> mean_test_score, there's overfitting\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OVERFITTING ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nChecking top 3 configurations for overfitting...\")\n",
    "print(\"(Train-Test gap > 0.05 indicates potential overfitting)\\n\")\n",
    "\n",
    "for i, idx in enumerate(cv_results_sorted.head(3).index, 1):\n",
    "    train_score = cv_results_sorted.loc[idx, 'mean_train_score']\n",
    "    test_score = cv_results_sorted.loc[idx, 'mean_test_score']\n",
    "    gap = train_score - test_score\n",
    "    \n",
    "    print(f\"Configuration {i}:\")\n",
    "    print(f\"  Train Score: {train_score:.4f}\")\n",
    "    print(f\"  Test Score:  {test_score:.4f}\")\n",
    "    print(f\"  Gap:         {gap:.4f}\", end=\"\")\n",
    "    \n",
    "    if gap > 0.05:\n",
    "        print(\" [WARNING] Potential overfitting detected!\")\n",
    "    else:\n",
    "        print(\" [OK] Good generalization\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dqs9l2l2gs",
   "metadata": {},
   "source": [
    "## **Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qzesw9ecmxl",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL LSTM MODEL EVALUATION ON TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get the best model (already retrained on full training set)\n",
    "best_lstm_model = grid_search_lstm.best_estimator_\n",
    "\n",
    "# Predict on test set\n",
    "print(\"\\nGenerating predictions on test set...\")\n",
    "y_pred_lstm = best_lstm_model.predict(X_test_padded)\n",
    "\n",
    "# Calculate all required metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_lstm)\n",
    "precision = precision_score(y_test, y_pred_lstm)\n",
    "recall = recall_score(y_test, y_pred_lstm)\n",
    "f1 = f1_score(y_test, y_pred_lstm)\n",
    "kappa = cohen_kappa_score(y_test, y_pred_lstm)\n",
    "\n",
    "# Display metrics in a nice table\n",
    "print(\"\\nLSTM Model Performance Metrics:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Metric':<25} {'Score':<15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Accuracy':<25} {accuracy:.4f}\")\n",
    "print(f\"{'Precision':<25} {precision:.4f}\")\n",
    "print(f\"{'Recall':<25} {recall:.4f}\")\n",
    "print(f\"{'F1-Score':<25} {f1:.4f}\")\n",
    "print(f\"{'Cohen\\'s Kappa':<25} {kappa:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(\"-\" * 60)\n",
    "print(classification_report(y_test, y_pred_lstm, target_names=['Negative (0)', 'Positive (1)']))\n",
    "\n",
    "# Compare with baseline\n",
    "print(\"\\nComparison with Baseline:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Baseline (Dummy Classifier):  0.5220\")\n",
    "print(f\"DNN Model Accuracy:            0.8187\")\n",
    "print(f\"LSTM Model Accuracy:           {accuracy:.4f}\")\n",
    "\n",
    "if accuracy > 0.8187:\n",
    "    improvement = ((accuracy - 0.8187) / 0.8187) * 100\n",
    "    print(f\"\\n[OK] LSTM outperforms DNN by {improvement:.2f}%\")\n",
    "elif accuracy < 0.8187:\n",
    "    decrease = ((0.8187 - accuracy) / 0.8187) * 100\n",
    "    print(f\"\\n[NOTE] LSTM underperforms DNN by {decrease:.2f}%\")\n",
    "else:\n",
    "    print(f\"\\n[NOTE] LSTM and DNN have similar performance\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rgfokayfq9g",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8wvkyr1js",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_lstm)\n",
    "\n",
    "# Plot confusion matrix with enhanced styling\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'],\n",
    "            cbar_kws={'label': 'Count'},\n",
    "            annot_kws={'size': 16, 'weight': 'bold'},\n",
    "            linewidths=2,\n",
    "            linecolor='white')\n",
    "\n",
    "plt.title('LSTM Model - Confusion Matrix', fontsize=18, fontweight='bold', pad=20)\n",
    "plt.ylabel('True Label', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "output_dir = '../outputs/figures'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = f'{output_dir}/lstm_confusion_matrix.png'\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"Confusion matrix saved to: {output_path}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print detailed confusion matrix statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONFUSION MATRIX STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"\\n{'Metric':<30} {'Count':<10} {'Percentage':<15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'True Negatives (TN)':<30} {tn:>5}      {tn/len(y_test)*100:>6.2f}%\")\n",
    "print(f\"{'False Positives (FP)':<30} {fp:>5}      {fp/len(y_test)*100:>6.2f}%\")\n",
    "print(f\"{'False Negatives (FN)':<30} {fn:>5}      {fn/len(y_test)*100:>6.2f}%\")\n",
    "print(f\"{'True Positives (TP)':<30} {tp:>5}      {tp/len(y_test)*100:>6.2f}%\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Total Samples':<30} {len(y_test):>5}\")\n",
    "\n",
    "# Calculate error rates\n",
    "print(f\"\\n{'Error Analysis':<30} {'Value':<15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'False Positive Rate (FPR)':<30} {fp/(fp+tn):.4f}\")\n",
    "print(f\"{'False Negative Rate (FNR)':<30} {fn/(fn+tp):.4f}\")\n",
    "print(f\"{'Specificity (TNR)':<30} {tn/(tn+fp):.4f}\")\n",
    "print(f\"{'Sensitivity (TPR/Recall)':<30} {tp/(tp+fn):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\nInterpretation:\")\n",
    "if fp < fn:\n",
    "    print(\"  - Model is more conservative (fewer false alarms)\")\n",
    "    print(\"  - Better at avoiding false positives than false negatives\")\n",
    "elif fp > fn:\n",
    "    print(\"  - Model is more liberal (more false alarms)\")\n",
    "    print(\"  - Better at avoiding false negatives than false positives\")\n",
    "else:\n",
    "    print(\"  - Model has balanced error distribution\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68gz835jol2",
   "metadata": {},
   "source": [
    "### Cohen's Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t3ww1qgwzd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohen's Kappa provides a measure of agreement between predicted and true labels\n",
    "# accounting for agreement that could occur by chance\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"COHEN'S KAPPA INTERPRETATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nCohen's Kappa Score: {kappa:.4f}\")\n",
    "\n",
    "# Interpretation scale\n",
    "print(\"\\nInterpretation Scale:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"  < 0.00:      Poor agreement (worse than chance)\")\n",
    "print(\"  0.00 - 0.20: Slight agreement\")\n",
    "print(\"  0.21 - 0.40: Fair agreement\")\n",
    "print(\"  0.41 - 0.60: Moderate agreement\")\n",
    "print(\"  0.61 - 0.80: Substantial agreement\")\n",
    "print(\"  0.81 - 1.00: Almost perfect agreement\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Determine interpretation\n",
    "if kappa < 0:\n",
    "    interpretation = \"Poor (worse than random)\"\n",
    "    level = \"[POOR]\"\n",
    "    description = \"The model performs worse than random guessing\"\n",
    "elif kappa < 0.20:\n",
    "    interpretation = \"Slight\"\n",
    "    level = \"[SLIGHT]\"\n",
    "    description = \"The model shows minimal agreement beyond chance\"\n",
    "elif kappa < 0.40:\n",
    "    interpretation = \"Fair\"\n",
    "    level = \"[FAIR]\"\n",
    "    description = \"The model shows fair agreement beyond chance\"\n",
    "elif kappa < 0.60:\n",
    "    interpretation = \"Moderate\"\n",
    "    level = \"[MODERATE]\"\n",
    "    description = \"The model shows moderate agreement beyond chance\"\n",
    "elif kappa < 0.80:\n",
    "    interpretation = \"Substantial\"\n",
    "    level = \"[SUBSTANTIAL]\"\n",
    "    description = \"The model shows substantial agreement beyond chance\"\n",
    "else:\n",
    "    interpretation = \"Almost Perfect\"\n",
    "    level = \"[EXCELLENT]\"\n",
    "    description = \"The model shows almost perfect agreement beyond chance\"\n",
    "\n",
    "print(f\"\\n{level} Model Classification: {interpretation.upper()}\")\n",
    "print(f\"\\nWhat this means:\")\n",
    "print(f\"   {description}.\")\n",
    "print(f\"   The predictions are {interpretation.lower()} in agreement with the true labels,\")\n",
    "print(f\"   even after accounting for agreements that could happen by random chance.\")\n",
    "\n",
    "# Additional context\n",
    "print(f\"\\nContext:\")\n",
    "if kappa >= 0.60:\n",
    "    print(\"   This is a GOOD result for sentiment analysis tasks.\")\n",
    "    print(\"   The model demonstrates reliable predictive performance.\")\n",
    "elif kappa >= 0.40:\n",
    "    print(\"   This is a MODERATE result for sentiment analysis tasks.\")\n",
    "    print(\"   The model shows reasonable predictive capability but has room for improvement.\")\n",
    "else:\n",
    "    print(\"   This result suggests the model needs improvement.\")\n",
    "    print(\"   Consider reviewing features, architecture, or hyperparameters.\")\n",
    "\n",
    "# Calculate expected accuracy by chance\n",
    "n = len(y_test)\n",
    "p_yes_actual = sum(y_test) / n\n",
    "p_no_actual = 1 - p_yes_actual\n",
    "p_yes_pred = sum(y_pred_lstm) / n\n",
    "p_no_pred = 1 - p_yes_pred\n",
    "p_expected = (p_yes_actual * p_yes_pred) + (p_no_actual * p_no_pred)\n",
    "\n",
    "print(f\"\\nChance Agreement Analysis:\")\n",
    "print(f\"   Observed Accuracy:    {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"   Expected by Chance:   {p_expected:.4f} ({p_expected*100:.2f}%)\")\n",
    "print(f\"   Improvement:          {(accuracy - p_expected):.4f} ({(accuracy - p_expected)*100:.2f}%)\")\n",
    "print(f\"   Kappa (normalized):   {kappa:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LSTM MODEL EVALUATION COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14cd0ec",
   "metadata": {},
   "source": [
    "# **Vanilla Recurrent Neural Network (RNN)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b98ca",
   "metadata": {},
   "source": [
    "## **Text Tokenization and Padding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15df0cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing tokenizer for Vanilla RNN...\n",
      "\n",
      "Sequence Length Statistics:\n",
      "  Min length: 0\n",
      "  Max length: 41\n",
      "  Mean length: 6.12\n",
      "  90th percentile: 11\n",
      "\n",
      "Tokenization Complete!\n",
      "  Vocabulary size (actual): 3576\n",
      "  Vocabulary size (used): 3576\n",
      "  Max sequence length: 11\n",
      "  Training data shape: (2180, 11)\n",
      "  Test data shape: (546, 11)\n",
      "\n",
      "Note: Using 90th percentile (shorter sequences) for Vanilla RNN\n",
      "      This helps mitigate vanishing gradient problems.\n"
     ]
    }
   ],
   "source": [
    "# For RNN models, we need to convert text into sequences of integers\n",
    "# and then pad them to ensure uniform length.\n",
    "# RNN uses SHORTER sequences than LSTM due to vanishing gradient issues.\n",
    "\n",
    "print(\"Initializing tokenizer for Vanilla RNN...\")\n",
    "\n",
    "# Initialize the tokenizer with a vocabulary size limit\n",
    "# Using 4000 words to balance between coverage and overfitting prevention\n",
    "vocab_size_rnn = 4000\n",
    "\n",
    "tokenizer_rnn = Tokenizer(num_words=vocab_size_rnn, oov_token='<OOV>')\n",
    "\n",
    "# Fit the tokenizer ONLY on training data\n",
    "tokenizer_rnn.fit_on_texts(X_train)\n",
    "\n",
    "# Convert text to sequences of integers\n",
    "X_train_seq_rnn = tokenizer_rnn.texts_to_sequences(X_train)\n",
    "X_test_seq_rnn = tokenizer_rnn.texts_to_sequences(X_test)\n",
    "\n",
    "# Calculate max sequence length using 90th percentile for RNN (shorter than LSTM)\n",
    "# This helps mitigate vanishing gradient problems in Vanilla RNN\n",
    "sequence_lengths_rnn = [len(seq) for seq in X_train_seq_rnn]\n",
    "max_length_rnn = int(np.percentile(sequence_lengths_rnn, 90))\n",
    "\n",
    "print(f\"\\nSequence Length Statistics:\")\n",
    "print(f\"  Min length: {np.min(sequence_lengths_rnn)}\")\n",
    "print(f\"  Max length: {np.max(sequence_lengths_rnn)}\")\n",
    "print(f\"  Mean length: {np.mean(sequence_lengths_rnn):.2f}\")\n",
    "print(f\"  90th percentile: {max_length_rnn}\")\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "X_train_padded_rnn = pad_sequences(X_train_seq_rnn, maxlen=max_length_rnn, padding='post', truncating='post')\n",
    "X_test_padded_rnn = pad_sequences(X_test_seq_rnn, maxlen=max_length_rnn, padding='post', truncating='post')\n",
    "\n",
    "# Print tokenization results\n",
    "actual_vocab_size_rnn = len(tokenizer_rnn.word_index) + 1  # +1 for padding token\n",
    "print(f\"\\nTokenization Complete!\")\n",
    "print(f\"  Vocabulary size (actual): {actual_vocab_size_rnn}\")\n",
    "print(f\"  Vocabulary size (used): {min(actual_vocab_size_rnn, vocab_size_rnn)}\")\n",
    "print(f\"  Max sequence length: {max_length_rnn}\")\n",
    "print(f\"  Training data shape: {X_train_padded_rnn.shape}\")\n",
    "print(f\"  Test data shape: {X_test_padded_rnn.shape}\")\n",
    "\n",
    "print(\"\\nNote: Using 90th percentile (shorter sequences) for Vanilla RNN\")\n",
    "print(\"      This helps mitigate vanishing gradient problems.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75a86a1",
   "metadata": {},
   "source": [
    "## **Building the Vanilla RNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4cb500b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Vanilla RNN Model Architecture...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/tera/semester8/cediii/IntegrativeTaskII-Nieto_Urbina_Velez/venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "2025-11-20 08:09:31.396702: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">178,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,752</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_layer (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │       \u001b[38;5;34m178,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_layer (\u001b[38;5;33mSimpleRNN\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │         \u001b[38;5;34m4,752\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m49\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">183,601</span> (717.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m183,601\u001b[0m (717.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">183,601</span> (717.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m183,601\u001b[0m (717.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "============================================================\n",
      "MODEL CHARACTERISTICS\n",
      "============================================================\n",
      "  Total parameters: 183,601\n",
      "  Architecture: Embedding -> SpatialDropout -> SimpleRNN -> Dropout -> Dense\n",
      "  Key difference from LSTM: No memory cells, simpler gating\n",
      "  Optimization: Smaller units and higher dropout than LSTM\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def create_rnn_model(vocab_size, embedding_dim=50, rnn_units=48, dropout_rate=0.5, optimizer='adam'):\n",
    "    \"\"\"\n",
    "    Creates a simple Vanilla RNN model for sentiment classification.\n",
    "\n",
    "    ANTI-OVERFITTING MEASURES:\n",
    "    - Small embedding dimension (50)\n",
    "    - Single SimpleRNN layer with moderate units (48 default)\n",
    "    - Aggressive dropout (0.5 default)\n",
    "    - SpatialDropout1D for embeddings\n",
    "    - L2 regularization on Dense layer\n",
    "    - Smaller capacity than LSTM (RNNs overfit more easily)\n",
    "\n",
    "    DESIGN RATIONALE:\n",
    "    - Vanilla RNN lacks memory cells, so it needs less capacity\n",
    "    - More prone to vanishing gradients, so keep architecture simple\n",
    "    - Higher dropout compensates for lack of gating mechanisms\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    vocab_size : int\n",
    "        Size of the vocabulary\n",
    "    embedding_dim : int\n",
    "        Dimension of word embeddings (default: 50)\n",
    "    rnn_units : int\n",
    "        Number of RNN units (default: 48, smaller than LSTM)\n",
    "    dropout_rate : float\n",
    "        Dropout rate (default: 0.5, higher than LSTM)\n",
    "    optimizer : str\n",
    "        Optimizer to use (default: 'adam')\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    model : Sequential\n",
    "        Compiled Vanilla RNN model\n",
    "    \"\"\"\n",
    "    import tensorflow as tf\n",
    "\n",
    "    model = Sequential([\n",
    "        # Embedding layer - learns word representations\n",
    "        Embedding(input_dim=vocab_size,\n",
    "                  output_dim=embedding_dim,\n",
    "                  input_length=max_length_rnn,\n",
    "                  name='embedding_layer'),\n",
    "\n",
    "        # Spatial dropout for embeddings (more effective than regular dropout)\n",
    "        SpatialDropout1D(dropout_rate * 0.5, name='spatial_dropout'),\n",
    "\n",
    "        # Single SimpleRNN layer - AVOID stacking (causes severe overfitting)\n",
    "        SimpleRNN(units=rnn_units,\n",
    "                  dropout=dropout_rate * 0.4,           # Input dropout\n",
    "                  recurrent_dropout=dropout_rate * 0.3, # Recurrent dropout\n",
    "                  return_sequences=False,                # Only return final output\n",
    "                  name='rnn_layer'),\n",
    "\n",
    "        # Regular dropout before dense layer (aggressive)\n",
    "        Dropout(dropout_rate, name='dropout'),\n",
    "\n",
    "        # Output layer with L2 regularization\n",
    "        Dense(1, activation='sigmoid',\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(0.001),\n",
    "              name='output_layer')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create a sample model to visualize architecture\n",
    "print(\"Building Vanilla RNN Model Architecture...\\n\")\n",
    "sample_rnn_model = create_rnn_model(\n",
    "    vocab_size=min(actual_vocab_size_rnn, vocab_size_rnn),\n",
    "    embedding_dim=50,\n",
    "    rnn_units=48\n",
    ")\n",
    "\n",
    "# Build the model explicitly with input shape to show parameters\n",
    "sample_rnn_model.build(input_shape=(None, max_length_rnn))\n",
    "\n",
    "print(sample_rnn_model.summary())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL CHARACTERISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  Total parameters: {sample_rnn_model.count_params():,}\")\n",
    "print(f\"  Architecture: Embedding -> SpatialDropout -> SimpleRNN -> Dropout -> Dense\")\n",
    "print(f\"  Key difference from LSTM: No memory cells, simpler gating\")\n",
    "print(f\"  Optimization: Smaller units and higher dropout than LSTM\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db22caed",
   "metadata": {},
   "source": [
    "## **Hyperparameter Tuning with GridSearchCV**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02e6ee56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VANILLA RNN - HYPERPARAMETER TUNING SETUP\n",
      "============================================================\n",
      "\n",
      "Parameter grid:\n",
      "  batch_size......................... [32, 64]\n",
      "  epochs............................. [15, 20]\n",
      "  model__embedding_dim............... [50]\n",
      "  model__rnn_units................... [32, 48]\n",
      "  model__dropout_rate................ [0.5, 0.6]\n",
      "  model__optimizer................... ['adam']\n",
      "\n",
      "Total combinations to test: 16\n",
      "Cross-validation folds: 3\n",
      "Total model trainings: 48\n",
      "\n",
      "Key differences from LSTM:\n",
      "  - RNN units: 32-48 (vs LSTM: 64-96)\n",
      "  - Dropout rate: 0.5-0.6 (vs LSTM: 0.4-0.5)\n",
      "  - Rationale: RNN has simpler architecture, needs more regularization\n",
      "\n",
      "Estimated time: 10-20 minutes (depending on hardware)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Store parameters as constants to avoid serialization issues\n",
    "RNN_VOCAB_SIZE = min(actual_vocab_size_rnn, vocab_size_rnn)\n",
    "RNN_MAX_LENGTH = max_length_rnn\n",
    "\n",
    "# Wrap the model for sklearn compatibility\n",
    "def create_rnn_wrapper(embedding_dim=50, rnn_units=48, dropout_rate=0.5, optimizer='adam'):\n",
    "    \"\"\"\n",
    "    Wrapper function for KerasClassifier.\n",
    "    Uses module-level constants to avoid serialization issues with multiprocessing.\n",
    "    \"\"\"\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Embedding, SimpleRNN, SpatialDropout1D, Dropout, Input\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add Input layer explicitly to ensure model is properly built\n",
    "    model.add(Input(shape=(RNN_MAX_LENGTH,)))\n",
    "\n",
    "    # Embedding layer - learns word representations\n",
    "    model.add(Embedding(input_dim=RNN_VOCAB_SIZE,\n",
    "                        output_dim=embedding_dim))\n",
    "\n",
    "    # Spatial dropout for embeddings (more effective than regular dropout)\n",
    "    model.add(SpatialDropout1D(dropout_rate * 0.5))\n",
    "\n",
    "    # Single SimpleRNN layer - AVOID stacking multiple RNNs (causes overfitting)\n",
    "    model.add(SimpleRNN(units=rnn_units,\n",
    "                        dropout=dropout_rate * 0.4,           # Input dropout\n",
    "                        recurrent_dropout=dropout_rate * 0.3))# Recurrent dropout\n",
    "\n",
    "    # Regular dropout before dense layer\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output layer with L2 regularization\n",
    "    model.add(Dense(1, activation='sigmoid',\n",
    "                    kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create KerasClassifier wrapper\n",
    "keras_rnn_model = KerasClassifier(\n",
    "    model=create_rnn_wrapper,\n",
    "    embedding_dim=50,\n",
    "    rnn_units=48,\n",
    "    dropout_rate=0.5,\n",
    "    optimizer='adam',\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# MINIMAL parameter grid - RNN needs careful tuning\n",
    "# Smaller units and higher dropout than LSTM due to architectural simplicity\n",
    "param_grid_rnn = {\n",
    "    'batch_size': [32, 64],                        # 2 values\n",
    "    'epochs': [15, 20],                            # 2 values\n",
    "    'model__embedding_dim': [50],                  # 1 value - keep fixed\n",
    "    'model__rnn_units': [32, 48],                  # 2 values - SMALLER than LSTM (64-96)\n",
    "    'model__dropout_rate': [0.5, 0.6],             # 2 values - MORE aggressive than LSTM (0.4-0.5)\n",
    "    'model__optimizer': ['adam']                    # 1 value - adam is best\n",
    "}\n",
    "\n",
    "# Calculate total combinations\n",
    "total_combinations_rnn = np.prod([len(v) for v in param_grid_rnn.values()])\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"VANILLA RNN - HYPERPARAMETER TUNING SETUP\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nParameter grid:\")\n",
    "for key, value in param_grid_rnn.items():\n",
    "    print(f\"  {key:.<35} {value}\")\n",
    "print(f\"\\nTotal combinations to test: {total_combinations_rnn}\")\n",
    "print(f\"Cross-validation folds: 3\")\n",
    "print(f\"Total model trainings: {total_combinations_rnn * 3}\")\n",
    "\n",
    "print(\"\\nKey differences from LSTM:\")\n",
    "print(\"  - RNN units: 32-48 (vs LSTM: 64-96)\")\n",
    "print(\"  - Dropout rate: 0.5-0.6 (vs LSTM: 0.4-0.5)\")\n",
    "print(\"  - Rationale: RNN has simpler architecture, needs more regularization\")\n",
    "\n",
    "print(\"\\nEstimated time: 10-20 minutes (depending on hardware)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0aac7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Grid Search for Vanilla RNN...\n",
      "Using 3-fold cross-validation with aggressive regularization...\n",
      "NOTE: Running sequentially (n_jobs=1) to avoid serialization issues.\n",
      "This will take some time. Please be patient.\n",
      "\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV] END batch_size=32, epochs=15, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   4.8s\n",
      "[CV] END batch_size=32, epochs=15, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   4.2s\n",
      "[CV] END batch_size=32, epochs=15, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   4.4s\n",
      "[CV] END batch_size=32, epochs=15, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   4.5s\n",
      "[CV] END batch_size=32, epochs=15, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   4.2s\n",
      "[CV] END batch_size=32, epochs=15, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   4.2s\n",
      "[CV] END batch_size=32, epochs=15, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   4.4s\n",
      "[CV] END batch_size=32, epochs=15, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   5.0s\n",
      "[CV] END batch_size=32, epochs=15, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   4.6s\n",
      "[CV] END batch_size=32, epochs=15, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   4.6s\n",
      "[CV] END batch_size=32, epochs=15, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   5.3s\n",
      "[CV] END batch_size=32, epochs=15, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   5.4s\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   6.0s\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   5.8s\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   5.5s\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   5.6s\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   5.1s\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   5.5s\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   5.7s\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   6.0s\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   5.3s\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   5.4s\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   5.6s\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   5.7s\n",
      "[CV] END batch_size=64, epochs=15, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   3.4s\n",
      "[CV] END batch_size=64, epochs=15, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   3.3s\n",
      "[CV] END batch_size=64, epochs=15, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   3.8s\n",
      "[CV] END batch_size=64, epochs=15, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   3.7s\n",
      "[CV] END batch_size=64, epochs=15, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   3.7s\n",
      "[CV] END batch_size=64, epochs=15, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   3.5s\n",
      "[CV] END batch_size=64, epochs=15, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   4.6s\n",
      "[CV] END batch_size=64, epochs=15, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   4.1s\n",
      "[CV] END batch_size=64, epochs=15, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   3.6s\n",
      "[CV] END batch_size=64, epochs=15, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   3.5s\n",
      "[CV] END batch_size=64, epochs=15, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   4.0s\n",
      "[CV] END batch_size=64, epochs=15, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   3.6s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   4.1s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   3.8s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   3.7s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   4.3s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   3.8s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.5, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   3.8s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   5.0s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   4.1s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=32; total time=   4.0s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   3.9s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   4.6s\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.6, model__embedding_dim=50, model__optimizer=adam, model__rnn_units=48; total time=   4.0s\n",
      "\n",
      "============================================================\n",
      "Grid Search complete!\n",
      "Time elapsed: 3.81 minutes\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize GridSearchCV\n",
    "# NOTE: Using n_jobs=1 to avoid multiprocessing serialization issues with Keras models\n",
    "grid_search_rnn = GridSearchCV(\n",
    "    estimator=keras_rnn_model,\n",
    "    param_grid=param_grid_rnn,\n",
    "    cv=3,                    # 3-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    n_jobs=1,                # Sequential execution (avoids serialization issues)\n",
    "    verbose=2,               # Show progress\n",
    "    return_train_score=True  # Track training scores to detect overfitting\n",
    ")\n",
    "\n",
    "print(\"\\nStarting Grid Search for Vanilla RNN...\")\n",
    "print(\"Using 3-fold cross-validation with aggressive regularization...\")\n",
    "print(\"NOTE: Running sequentially (n_jobs=1) to avoid serialization issues.\")\n",
    "print(\"This will take some time. Please be patient.\\n\")\n",
    "\n",
    "# Fit the grid search\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "grid_search_rnn.fit(X_train_padded_rnn, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Grid Search complete!\")\n",
    "print(f\"Time elapsed: {elapsed_time/60:.2f} minutes\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afa6c06",
   "metadata": {},
   "source": [
    "### Review Tuning Results and Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8962645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VANILLA RNN - GRID SEARCH RESULTS\n",
      "============================================================\n",
      "\n",
      "Best Cross-Validation Accuracy: 0.7440\n",
      "\n",
      "Best Parameters found:\n",
      "  batch_size.............................. 32\n",
      "  epochs.................................. 20\n",
      "  model__dropout_rate..................... 0.6\n",
      "  model__embedding_dim.................... 50\n",
      "  model__optimizer........................ adam\n",
      "  model__rnn_units........................ 32\n",
      "\n",
      "============================================================\n",
      "TOP 5 PARAMETER COMBINATIONS\n",
      "============================================================\n",
      "\n",
      "Rank | Test Score | Train Score | Std Dev | Gap\n",
      "------------------------------------------------------------\n",
      "   1 | 0.7440     | 0.9901      | 0.0277  | 0.2461\n",
      "   2 | 0.7436     | 0.9855      | 0.0084  | 0.2420\n",
      "   3 | 0.7376     | 0.9897      | 0.0342  | 0.2521\n",
      "   4 | 0.7330     | 0.9950      | 0.0261  | 0.2619\n",
      "   5 | 0.7271     | 0.9927      | 0.0141  | 0.2656\n",
      "\n",
      "============================================================\n",
      "OVERFITTING ANALYSIS (Train-Test Gap)\n",
      "============================================================\n",
      "\n",
      "Analyzing top 3 configurations...\n",
      "(Gap > 0.05 indicates potential overfitting)\n",
      "\n",
      "Config     Train Score    Test Score     Gap        Status\n",
      "-----------------------------------------------------------------\n",
      "1          0.9901         0.7440         0.2461     [SEVERE]\n",
      "2          0.9855         0.7436         0.2420     [SEVERE]\n",
      "3          0.9897         0.7376         0.2521     [SEVERE]\n",
      "\n",
      "Interpretation:\n",
      "  Gap <= 0.05:  Good generalization\n",
      "  Gap 0.05-0.10: Potential overfitting\n",
      "  Gap > 0.10:   Severe overfitting\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Display best parameters and CV score\n",
    "print(\"=\"*60)\n",
    "print(\"VANILLA RNN - GRID SEARCH RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nBest Cross-Validation Accuracy: {grid_search_rnn.best_score_:.4f}\")\n",
    "print(\"\\nBest Parameters found:\")\n",
    "for param, value in grid_search_rnn.best_params_.items():\n",
    "    print(f\"  {param:.<40} {value}\")\n",
    "\n",
    "# Analyze CV results to check for overfitting\n",
    "cv_results_rnn = pd.DataFrame(grid_search_rnn.cv_results_)\n",
    "cv_results_sorted_rnn = cv_results_rnn.sort_values('rank_test_score')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP 5 PARAMETER COMBINATIONS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nRank | Test Score | Train Score | Std Dev | Gap\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i, idx in enumerate(cv_results_sorted_rnn.head(5).index, 1):\n",
    "    test_score = cv_results_sorted_rnn.loc[idx, 'mean_test_score']\n",
    "    train_score = cv_results_sorted_rnn.loc[idx, 'mean_train_score']\n",
    "    std_score = cv_results_sorted_rnn.loc[idx, 'std_test_score']\n",
    "    gap = train_score - test_score\n",
    "\n",
    "    print(f\"{i:>4} | {test_score:.4f}     | {train_score:.4f}      | {std_score:.4f}  | {gap:.4f}\")\n",
    "\n",
    "# Check for overfitting: if mean_train_score >> mean_test_score, there's overfitting\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OVERFITTING ANALYSIS (Train-Test Gap)\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nAnalyzing top 3 configurations...\")\n",
    "print(\"(Gap > 0.05 indicates potential overfitting)\\n\")\n",
    "\n",
    "print(f\"{'Config':<10} {'Train Score':<14} {'Test Score':<14} {'Gap':<10} {'Status'}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for i, idx in enumerate(cv_results_sorted_rnn.head(3).index, 1):\n",
    "    train_score = cv_results_sorted_rnn.loc[idx, 'mean_train_score']\n",
    "    test_score = cv_results_sorted_rnn.loc[idx, 'mean_test_score']\n",
    "    gap = train_score - test_score\n",
    "\n",
    "    if gap <= 0.05:\n",
    "        status = \"[OK] Good\"\n",
    "    elif gap <= 0.10:\n",
    "        status = \"[WARNING]\"\n",
    "    else:\n",
    "        status = \"[SEVERE]\"\n",
    "\n",
    "    print(f\"{i:<10} {train_score:<14.4f} {test_score:<14.4f} {gap:<10.4f} {status}\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  Gap <= 0.05:  Good generalization\")\n",
    "print(\"  Gap 0.05-0.10: Potential overfitting\")\n",
    "print(\"  Gap > 0.10:   Severe overfitting\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8dbbc4",
   "metadata": {},
   "source": [
    "## **Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e0abb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL VANILLA RNN MODEL EVALUATION ON TEST SET\n",
      "============================================================\n",
      "\n",
      "Generating predictions on test set...\n",
      "\n",
      "Vanilla RNN Model Performance Metrics:\n",
      "============================================================\n",
      "Metric                    Score          \n",
      "------------------------------------------------------------\n",
      "Accuracy                  0.7692\n",
      "Precision                 0.7633\n",
      "Recall                    0.7855\n",
      "F1-Score                  0.7742\n",
      "Cohen's Kappa             0.5383\n",
      "============================================================\n",
      "\n",
      "Detailed Classification Report:\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Negative (0)       0.78      0.75      0.76       271\n",
      "Positive (1)       0.76      0.79      0.77       275\n",
      "\n",
      "    accuracy                           0.77       546\n",
      "   macro avg       0.77      0.77      0.77       546\n",
      "weighted avg       0.77      0.77      0.77       546\n",
      "\n",
      "\n",
      "Comparison with Other Models:\n",
      "------------------------------------------------------------\n",
      "Baseline (Dummy Classifier):  0.5220\n",
      "DNN Model Accuracy:            0.8187\n",
      "Vanilla RNN Model Accuracy:    0.7692\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL VANILLA RNN MODEL EVALUATION ON TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get the best model (already retrained on full training set)\n",
    "best_rnn_model = grid_search_rnn.best_estimator_\n",
    "\n",
    "# Predict on test set\n",
    "print(\"\\nGenerating predictions on test set...\")\n",
    "y_pred_rnn = best_rnn_model.predict(X_test_padded_rnn)\n",
    "\n",
    "# Calculate all required metrics\n",
    "accuracy_rnn = accuracy_score(y_test, y_pred_rnn)\n",
    "precision_rnn = precision_score(y_test, y_pred_rnn)\n",
    "recall_rnn = recall_score(y_test, y_pred_rnn)\n",
    "f1_rnn = f1_score(y_test, y_pred_rnn)\n",
    "kappa_rnn = cohen_kappa_score(y_test, y_pred_rnn)\n",
    "\n",
    "# Display metrics in a nice table\n",
    "print(\"\\nVanilla RNN Model Performance Metrics:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Metric':<25} {'Score':<15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Accuracy':<25} {accuracy_rnn:.4f}\")\n",
    "print(f\"{'Precision':<25} {precision_rnn:.4f}\")\n",
    "print(f\"{'Recall':<25} {recall_rnn:.4f}\")\n",
    "print(f\"{'F1-Score':<25} {f1_rnn:.4f}\")\n",
    "print(f\"{'Cohen\\'s Kappa':<25} {kappa_rnn:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(\"-\" * 60)\n",
    "print(classification_report(y_test, y_pred_rnn, target_names=['Negative (0)', 'Positive (1)']))\n",
    "\n",
    "# Compare with other models\n",
    "print(\"\\nComparison with Other Models:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Baseline (Dummy Classifier):  0.5220\")\n",
    "print(f\"DNN Model Accuracy:            0.8187\")\n",
    "print(f\"Vanilla RNN Model Accuracy:    {accuracy_rnn:.4f}\")\n",
    "\n",
    "# Store metrics for later comparison\n",
    "rnn_metrics = {\n",
    "    'model': 'Vanilla RNN',\n",
    "    'accuracy': accuracy_rnn,\n",
    "    'precision': precision_rnn,\n",
    "    'recall': recall_rnn,\n",
    "    'f1_score': f1_rnn,\n",
    "    'kappa': kappa_rnn\n",
    "}\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b51856",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbba9345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix saved to: ../outputs/figures/rnn_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CONFUSION MATRIX STATISTICS\n",
      "============================================================\n",
      "\n",
      "Metric                         Count      Percentage     \n",
      "------------------------------------------------------------\n",
      "True Negatives (TN)              204       37.36%\n",
      "False Positives (FP)              67       12.27%\n",
      "False Negatives (FN)              59       10.81%\n",
      "True Positives (TP)              216       39.56%\n",
      "------------------------------------------------------------\n",
      "Total Samples                    546\n",
      "\n",
      "Error Analysis                 Value          \n",
      "------------------------------------------------------------\n",
      "False Positive Rate (FPR)      0.2472\n",
      "False Negative Rate (FNR)      0.2145\n",
      "Specificity (TNR)              0.7528\n",
      "Sensitivity (TPR/Recall)       0.7855\n",
      "\n",
      "============================================================\n",
      "\n",
      "Interpretation:\n",
      "  - Model is more liberal (more false alarms)\n",
      "  - Better at avoiding false negatives than false positives\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create confusion matrix\n",
    "cm_rnn = confusion_matrix(y_test, y_pred_rnn)\n",
    "\n",
    "# Plot confusion matrix with enhanced styling (using Greens colormap for RNN)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_rnn, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'],\n",
    "            cbar_kws={'label': 'Count'},\n",
    "            annot_kws={'size': 16, 'weight': 'bold'},\n",
    "            linewidths=2,\n",
    "            linecolor='white')\n",
    "\n",
    "plt.title('Vanilla RNN Model - Confusion Matrix', fontsize=18, fontweight='bold', pad=20)\n",
    "plt.ylabel('True Label', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "output_dir = '../outputs/figures'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = f'{output_dir}/rnn_confusion_matrix.png'\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"Confusion matrix saved to: {output_path}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print detailed confusion matrix statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONFUSION MATRIX STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "tn, fp, fn, tp = cm_rnn.ravel()\n",
    "\n",
    "print(f\"\\n{'Metric':<30} {'Count':<10} {'Percentage':<15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'True Negatives (TN)':<30} {tn:>5}      {tn/len(y_test)*100:>6.2f}%\")\n",
    "print(f\"{'False Positives (FP)':<30} {fp:>5}      {fp/len(y_test)*100:>6.2f}%\")\n",
    "print(f\"{'False Negatives (FN)':<30} {fn:>5}      {fn/len(y_test)*100:>6.2f}%\")\n",
    "print(f\"{'True Positives (TP)':<30} {tp:>5}      {tp/len(y_test)*100:>6.2f}%\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Total Samples':<30} {len(y_test):>5}\")\n",
    "\n",
    "# Calculate error rates\n",
    "print(f\"\\n{'Error Analysis':<30} {'Value':<15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'False Positive Rate (FPR)':<30} {fp/(fp+tn):.4f}\")\n",
    "print(f\"{'False Negative Rate (FNR)':<30} {fn/(fn+tp):.4f}\")\n",
    "print(f\"{'Specificity (TNR)':<30} {tn/(tn+fp):.4f}\")\n",
    "print(f\"{'Sensitivity (TPR/Recall)':<30} {tp/(tp+fn):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\nInterpretation:\")\n",
    "if fp < fn:\n",
    "    print(\"  - Model is more conservative (fewer false alarms)\")\n",
    "    print(\"  - Better at avoiding false positives than false negatives\")\n",
    "elif fp > fn:\n",
    "    print(\"  - Model is more liberal (more false alarms)\")\n",
    "    print(\"  - Better at avoiding false negatives than false positives\")\n",
    "else:\n",
    "    print(\"  - Model has balanced error distribution\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45d4ab8",
   "metadata": {},
   "source": [
    "### Cohen's Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51114bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COHEN'S KAPPA INTERPRETATION\n",
      "============================================================\n",
      "\n",
      "Cohen's Kappa Score: 0.5383\n",
      "\n",
      "Interpretation Scale:\n",
      "------------------------------------------------------------\n",
      "  < 0.00:      Poor agreement (worse than chance)\n",
      "  0.00 - 0.20: Slight agreement\n",
      "  0.21 - 0.40: Fair agreement\n",
      "  0.41 - 0.60: Moderate agreement\n",
      "  0.61 - 0.80: Substantial agreement\n",
      "  0.81 - 1.00: Almost perfect agreement\n",
      "------------------------------------------------------------\n",
      "\n",
      "[MODERATE] Model Classification: MODERATE\n",
      "Overall Quality: GOOD\n",
      "\n",
      "What this means:\n",
      "   The model shows moderate agreement beyond chance.\n",
      "   The predictions are moderate in agreement with the true labels,\n",
      "   even after accounting for agreements that could happen by random chance.\n",
      "\n",
      "Context for Sentiment Analysis:\n",
      "   This is a MODERATE result for sentiment analysis tasks.\n",
      "   The model shows reasonable predictive capability but has room for improvement.\n",
      "\n",
      "Chance Agreement Analysis:\n",
      "   Observed Accuracy:    0.7692 (76.92%)\n",
      "   Expected by Chance:   0.5001 (50.01%)\n",
      "   Improvement:          0.2691 (26.91%)\n",
      "   Cohen's Kappa:        0.5383\n",
      "\n",
      "Kappa accounts for the chance agreement, providing a more\n",
      "robust measure of model performance than accuracy alone.\n",
      "\n",
      "============================================================\n",
      "VANILLA RNN MODEL SUMMARY\n",
      "============================================================\n",
      "\n",
      "Architecture Highlights:\n",
      "  - Vocabulary Size: 3,576\n",
      "  - Embedding Dimension: 50\n",
      "  - RNN Units: 32\n",
      "  - Dropout Rate: 0.6\n",
      "  - Sequence Length: 11 (90th percentile)\n",
      "  - Total Parameters: 181,489\n",
      "\n",
      "Training Configuration:\n",
      "  - Optimizer: adam\n",
      "  - Batch Size: 32\n",
      "  - Epochs: 20\n",
      "  - Loss Function: Binary Crossentropy\n",
      "\n",
      "Key Design Decisions:\n",
      "  1. Shorter sequences (90th percentile) to mitigate vanishing gradients\n",
      "  2. Smaller RNN units (32-48) compared to LSTM (64-96)\n",
      "  3. Higher dropout (0.5-0.6) to compensate for simpler architecture\n",
      "  4. Single RNN layer to avoid overfitting\n",
      "  5. L2 regularization on output layer\n",
      "\n",
      "Vanilla RNN vs LSTM:\n",
      "  - RNN: Simpler, faster, but prone to vanishing gradients\n",
      "  - LSTM: More complex, with memory cells and gates\n",
      "  - RNN: Better for shorter sequences and simpler patterns\n",
      "  - LSTM: Better for longer sequences and complex dependencies\n",
      "\n",
      "============================================================\n",
      "VANILLA RNN MODEL EVALUATION COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"COHEN'S KAPPA INTERPRETATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nCohen's Kappa Score: {kappa_rnn:.4f}\")\n",
    "\n",
    "# Interpretation scale (Landis & Koch, 1977)\n",
    "print(\"\\nInterpretation Scale:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"  < 0.00:      Poor agreement (worse than chance)\")\n",
    "print(\"  0.00 - 0.20: Slight agreement\")\n",
    "print(\"  0.21 - 0.40: Fair agreement\")\n",
    "print(\"  0.41 - 0.60: Moderate agreement\")\n",
    "print(\"  0.61 - 0.80: Substantial agreement\")\n",
    "print(\"  0.81 - 1.00: Almost perfect agreement\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Determine interpretation\n",
    "if kappa_rnn < 0:\n",
    "    interpretation = \"Poor (worse than random)\"\n",
    "    level = \"[POOR]\"\n",
    "    description = \"The model performs worse than random guessing\"\n",
    "    quality = \"NEEDS IMPROVEMENT\"\n",
    "elif kappa_rnn < 0.20:\n",
    "    interpretation = \"Slight\"\n",
    "    level = \"[SLIGHT]\"\n",
    "    description = \"The model shows minimal agreement beyond chance\"\n",
    "    quality = \"NEEDS IMPROVEMENT\"\n",
    "elif kappa_rnn < 0.40:\n",
    "    interpretation = \"Fair\"\n",
    "    level = \"[FAIR]\"\n",
    "    description = \"The model shows fair agreement beyond chance\"\n",
    "    quality = \"ACCEPTABLE\"\n",
    "elif kappa_rnn < 0.60:\n",
    "    interpretation = \"Moderate\"\n",
    "    level = \"[MODERATE]\"\n",
    "    description = \"The model shows moderate agreement beyond chance\"\n",
    "    quality = \"GOOD\"\n",
    "elif kappa_rnn < 0.80:\n",
    "    interpretation = \"Substantial\"\n",
    "    level = \"[SUBSTANTIAL]\"\n",
    "    description = \"The model shows substantial agreement beyond chance\"\n",
    "    quality = \"VERY GOOD\"\n",
    "else:\n",
    "    interpretation = \"Almost Perfect\"\n",
    "    level = \"[EXCELLENT]\"\n",
    "    description = \"The model shows almost perfect agreement beyond chance\"\n",
    "    quality = \"EXCELLENT\"\n",
    "\n",
    "print(f\"\\n{level} Model Classification: {interpretation.upper()}\")\n",
    "print(f\"Overall Quality: {quality}\")\n",
    "\n",
    "print(f\"\\nWhat this means:\")\n",
    "print(f\"   {description}.\")\n",
    "print(f\"   The predictions are {interpretation.lower()} in agreement with the true labels,\")\n",
    "print(f\"   even after accounting for agreements that could happen by random chance.\")\n",
    "\n",
    "# Additional context\n",
    "print(f\"\\nContext for Sentiment Analysis:\")\n",
    "if kappa_rnn >= 0.60:\n",
    "    print(\"   This is a GOOD result for sentiment analysis tasks.\")\n",
    "    print(\"   The model demonstrates reliable predictive performance.\")\n",
    "elif kappa_rnn >= 0.40:\n",
    "    print(\"   This is a MODERATE result for sentiment analysis tasks.\")\n",
    "    print(\"   The model shows reasonable predictive capability but has room for improvement.\")\n",
    "else:\n",
    "    print(\"   This result suggests the model needs improvement.\")\n",
    "    print(\"   Consider reviewing features, architecture, or hyperparameters.\")\n",
    "\n",
    "# Calculate expected accuracy by chance\n",
    "n = len(y_test)\n",
    "p_yes_actual = sum(y_test) / n\n",
    "p_no_actual = 1 - p_yes_actual\n",
    "p_yes_pred = sum(y_pred_rnn) / n\n",
    "p_no_pred = 1 - p_yes_pred\n",
    "p_expected = (p_yes_actual * p_yes_pred) + (p_no_actual * p_no_pred)\n",
    "\n",
    "print(f\"\\nChance Agreement Analysis:\")\n",
    "print(f\"   Observed Accuracy:    {accuracy_rnn:.4f} ({accuracy_rnn*100:.2f}%)\")\n",
    "print(f\"   Expected by Chance:   {p_expected:.4f} ({p_expected*100:.2f}%)\")\n",
    "print(f\"   Improvement:          {(accuracy_rnn - p_expected):.4f} ({(accuracy_rnn - p_expected)*100:.2f}%)\")\n",
    "print(f\"   Cohen's Kappa:        {kappa_rnn:.4f}\")\n",
    "\n",
    "print(\"\\nKappa accounts for the chance agreement, providing a more\")\n",
    "print(\"robust measure of model performance than accuracy alone.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VANILLA RNN MODEL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nArchitecture Highlights:\")\n",
    "print(f\"  - Vocabulary Size: {RNN_VOCAB_SIZE:,}\")\n",
    "print(f\"  - Embedding Dimension: {grid_search_rnn.best_params_['model__embedding_dim']}\")\n",
    "print(f\"  - RNN Units: {grid_search_rnn.best_params_['model__rnn_units']}\")\n",
    "print(f\"  - Dropout Rate: {grid_search_rnn.best_params_['model__dropout_rate']}\")\n",
    "print(f\"  - Sequence Length: {max_length_rnn} (90th percentile)\")\n",
    "print(f\"  - Total Parameters: {best_rnn_model.model_.count_params():,}\")\n",
    "\n",
    "print(\"\\nTraining Configuration:\")\n",
    "print(f\"  - Optimizer: {grid_search_rnn.best_params_['model__optimizer']}\")\n",
    "print(f\"  - Batch Size: {grid_search_rnn.best_params_['batch_size']}\")\n",
    "print(f\"  - Epochs: {grid_search_rnn.best_params_['epochs']}\")\n",
    "print(f\"  - Loss Function: Binary Crossentropy\")\n",
    "\n",
    "print(\"\\nKey Design Decisions:\")\n",
    "print(\"  1. Shorter sequences (90th percentile) to mitigate vanishing gradients\")\n",
    "print(\"  2. Smaller RNN units (32-48) compared to LSTM (64-96)\")\n",
    "print(\"  3. Higher dropout (0.5-0.6) to compensate for simpler architecture\")\n",
    "print(\"  4. Single RNN layer to avoid overfitting\")\n",
    "print(\"  5. L2 regularization on output layer\")\n",
    "\n",
    "print(\"\\nVanilla RNN vs LSTM:\")\n",
    "print(\"  - RNN: Simpler, faster, but prone to vanishing gradients\")\n",
    "print(\"  - LSTM: More complex, with memory cells and gates\")\n",
    "print(\"  - RNN: Better for shorter sequences and simpler patterns\")\n",
    "print(\"  - LSTM: Better for longer sequences and complex dependencies\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VANILLA RNN MODEL EVALUATION COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
